# -*- coding: utf-8 -*-
"""COE292_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/101pTv7-LtFd4IMn9LY4F4sv71iYvM-kO
"""

import numpy as np
import tensorflow as tf
from sklearn.utils import shuffle
from sklearn.model_selection import KFold, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
# Set a global random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Step 1: Load the dataset

drive.mount('/content/drive')
data_path = '/content/drive/My Drive/archive'
dataset = tf.keras.utils.image_dataset_from_directory(
    data_path,
    image_size=(28, 28),  # Resize images to 28x28
    batch_size=32,
    label_mode='categorical',  # One-hot encoded labels
    shuffle=True,
    seed=42  # Set seed for reproducibility
)

# Get the class names from the directory structure (folder names)
class_names = dataset.class_names
print(f"Class Names: {class_names}")

# Step 2: Convert dataset to numpy arrays
images = []
labels = []

for img_batch, lbl_batch in dataset:
    images.append(img_batch.numpy())
    labels.append(lbl_batch.numpy())

# Convert the list to numpy arrays
images = np.concatenate(images, axis=0)
labels = np.concatenate(labels, axis=0)

# Step 3: Separate images by class
class_labels = np.argmax(labels, axis=1)

# Step 4: Select 200 images from each class
selected_images = []
selected_labels = []

# Iterate through each class and select 200 images
for class_id in np.unique(class_labels):
    # Get all images corresponding to the current class
    class_images = images[class_labels == class_id]
    class_labels_ = labels[class_labels == class_id]

    # Randomly shuffle and select 200 images from this class
    class_images, class_labels_ = shuffle(class_images, class_labels_, random_state=42)
    selected_images.append(class_images[:200])
    selected_labels.append(class_labels_[:200])

# Step 5: Combine the selected images and labels
selected_images = np.concatenate(selected_images, axis=0)
selected_labels = np.concatenate(selected_labels, axis=0)

# Step 6: Shuffle the final dataset to mix the images from different classes
selected_images, selected_labels = shuffle(selected_images, selected_labels, random_state=42)

# Step 7: Normalize and flatten the images
selected_images = selected_images / 255.0  # Normalize images to [0, 1]
selected_images = selected_images.reshape(selected_images.shape[0], -1)  # Flatten the images

# Step 8: Split data into train and test sets (480 for training, 120 for testing)
x_train, x_test = selected_images[:480], selected_images[480:]
y_train, y_test = selected_labels[:480], selected_labels[480:]

# Step 9: Use K-fold Cross-Validation to find the best K value
kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation

# Store the accuracies for each K value
k_values = range(1, 40)  # Trying K values from 1 to 39
accuracies = []
misclassification_errors = []

# Test for different K values
for k in k_values:
    fold_accuracies = []  # List to store accuracy for each fold

    # Cross-validation loop
    for train_index, test_index in kf.split(selected_images):
        x_train_fold, x_test_fold = selected_images[train_index], selected_images[test_index]
        y_train_fold, y_test_fold = selected_labels[train_index], selected_labels[test_index]

        # Create the K-NN model with the current K value
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(x_train_fold, y_train_fold)  # Train the model

        y_pred = knn.predict(x_test_fold)  # Make predictions
        accuracy = accuracy_score(np.argmax(y_test_fold, axis=1), np.argmax(y_pred, axis=1))  # Calculate accuracy
        fold_accuracies.append(accuracy)  # Store the accuracy for this fold

    # Calculate average accuracy for this K value
    avg_accuracy = np.mean(fold_accuracies)
    accuracies.append(avg_accuracy)
    misclassification_errors.append(1 - avg_accuracy)  # Misclassification error is 1 - accuracy

# Plot the misclassification error vs K values
plt.figure(figsize=(10, 6))  # Increased figure width for better display
plt.plot(k_values, misclassification_errors, color='red',
         linestyle='dashed', marker='o',
         markerfacecolor='yellow', markersize=10)
plt.title('Error Rate Vs. K Value')
plt.xlabel('K Value')
plt.ylabel('Mean Error')
plt.grid(True)
plt.xticks(k_values)  # Ensure that all K values appear on the x-axis
plt.show()

# Step 10: Find the best K based on the lowest misclassification error
best_k = k_values[np.argmin(misclassification_errors)]
print(f"Best K value: {best_k} with Misclassification Error: {min(misclassification_errors):.4f}")

# Step 11: Model Performance Evaluation with best K value
# Use the best K value to train the final model
final_knn = KNeighborsClassifier(n_neighbors=best_k)
final_knn.fit(x_train, y_train)

# Make predictions on the test set
y_pred = final_knn.predict(x_test)

# Evaluate accuracy
accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))
print(f"Final Accuracy: {accuracy:.4f}")

# Confusion Matrix
cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))

# Plot confusion matrix
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'shrink': 1},
            xticklabels=class_names, yticklabels=class_names,
            annot_kws={"size": 10, "weight": 'bold'},
            linewidths=1, linecolor='black', square=True)
plt.title("Confusion Matrix", fontsize=18, pad=6)
plt.xlabel('Predicted label', fontsize=14, labelpad=3)
plt.ylabel('True label', fontsize=14, labelpad=3)
plt.tight_layout(pad=2)
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), target_names=class_names))

# Cross-Validation to ensure model generalization
cv_accuracies = cross_val_score(final_knn, selected_images, np.argmax(selected_labels, axis=1), cv=kf, scoring='accuracy')
print(f"Cross-Validation Accuracy Scores (5-fold): {cv_accuracies}")
print(f"Average Cross-Validation Accuracy: {np.mean(cv_accuracies):.4f}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score
from sklearn import svm
from sklearn.metrics import confusion_matrix, precision_score, recall_score
from sklearn.decomposition import PCA
from google.colab import drive
from collections import defaultdict
import tensorflow as tf

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Dataset Path
data_path = '/content/drive/My Drive/archive'

# Image Parameters
img_size = 64  # Resize to smaller dimensions to reduce memory usage
batch_size = 32

# Load Dataset
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_path,
    shuffle=False,  # Disable shuffling
    image_size=(img_size, img_size),
    batch_size=batch_size,
    labels='inferred',
    label_mode='int'
)

# Balanced Sampling Function with dynamic adjustment for insufficient samples
def balanced_sampling(dataset, samples_per_class):
    class_counts = defaultdict(int)
    x_balanced, y_balanced = [], []

    for img, lbl in dataset:
        img_np, lbl_np = img.numpy(), lbl.numpy()
        for i in range(len(lbl_np)):
            label = lbl_np[i]
            if class_counts[label] < samples_per_class:
                x_balanced.append(img_np[i])
                y_balanced.append(label)
                class_counts[label] += 1

    # Debugging: Check class distribution
    print("Class counts during sampling:", dict(class_counts))
    if len(class_counts) < len(np.unique(lbl_np)):
        print(f"Warning: Not all classes have {samples_per_class} samples.")
        samples_per_class = min(class_counts.values())
        print(f"Adjusted samples_per_class to {samples_per_class}.")

    return np.array(x_balanced), np.array(y_balanced)

# Split Dataset into Training and Testing
def split_dataset(ds, train_ratio=0.8):
    dataset_size = len(ds)
    train_size = int(train_ratio * dataset_size)
    test_size = dataset_size - train_size

    train_dataset = ds.take(train_size)
    test_dataset = ds.skip(train_size).take(test_size)

    return train_dataset, test_dataset

# Split the dataset
train_ds, test_ds = split_dataset(dataset)

# Apply Balanced Sampling to Training Dataset
train_images, train_labels = balanced_sampling(train_ds, samples_per_class=200)

# Dynamically Adjust Sampling for Test Dataset
try:
    test_images, test_labels = balanced_sampling(test_ds, samples_per_class=50)
except ValueError as e:
    print("Adjusting test sampling due to insufficient samples.")
    test_images, test_labels = balanced_sampling(test_ds, samples_per_class=10)  # Adjusted to 10 per class

# Normalize Images
train_images = train_images / 255.0
test_images = test_images / 255.0

# Flatten Images for SVM
train_images_flat = train_images.reshape(train_images.shape[0], -1)
test_images_flat = test_images.reshape(test_images.shape[0], -1)

# Check Unique Classes
print("Unique classes in train_labels:", np.unique(train_labels))
print("Unique classes in test_labels:", np.unique(test_labels))

# Apply PCA for Dimensionality Reduction
pca = PCA(n_components=100)  # Reduce to 100 dimensions
train_images_pca = pca.fit_transform(train_images_flat)
test_images_pca = pca.transform(test_images_flat)

# Train SVM Model
model = svm.SVC(kernel='linear')
svc = model.fit(train_images_pca, train_labels)

# Predict and Evaluate
predictions = model.predict(test_images_pca)
accuracy = model.score(test_images_pca, test_labels)
conf_matrix = confusion_matrix(test_labels, predictions)

# Print Results
print("Confusion Matrix")
print(conf_matrix)
print(f"Accuracy = {accuracy * 100}%")

# Calculate Precision and Recall
precision = precision_score(test_labels, predictions, average='weighted')
recall = recall_score(test_labels, predictions, average='weighted')

print(f"Precision: {precision * 100}%")
print(f"Recall: {recall * 100}%")

# Cross-Validation
cv_scores = cross_val_score(model, train_images_pca, train_labels, cv=5)
print("Cross-validation scores:", cv_scores)
print("Mean cross-validation score:", cv_scores.mean() * 100, "%")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_score, recall_score
import numpy as np
from google.colab import drive
import os

# Step 0: Enable full TensorFlow determinism
tf.config.experimental.enable_op_determinism()

# Set seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Step 1: Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Step 2: Specify the path to the dataset in Google Drive
data_path = '/content/drive/My Drive/archive'  # Update this path to your dataset folder in Google Drive

# Step 3: Load dataset from the directory
dataset = tf.keras.utils.image_dataset_from_directory(
    data_path,
    image_size=(28, 28),  # Resize images to match model input size
    batch_size=32,        # We can use a larger batch size here
    label_mode='categorical',  # Automatically one-hot encodes labels
    shuffle=False  # Shuffle the dataset
)

# Step 4: Limit dataset to 200 images from each class
class_limit = 200  # Set limit per class

# Create a new list to store selected images and labels
images = []
labels = []

# Iterate through each class and sample 200 images
for class_idx in range(len(dataset.class_names)):
    class_images = []
    class_labels = []

    for img, label in dataset.unbatch():
        if np.argmax(label) == class_idx:
            class_images.append(img.numpy())
            class_labels.append(label.numpy())

        # Stop when we reach the limit for each class
        if len(class_images) >= class_limit:
            break

    # Add selected class images and labels to the final list
    images.extend(class_images[:class_limit])
    labels.extend(class_labels[:class_limit])

# Convert the lists to numpy arrays
images = np.array(images)
labels = np.array(labels)

# Step 5: Split the data into 75% for training and 25% for testing
x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.25, random_state=42)

# Step 6: Define the CNN model
model = Sequential()

# Add convolutional layers
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# Flatten the feature map and add dense layers
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(len(dataset.class_names), activation='softmax'))  # Output layer

# Compile the model
batch_size = 128
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=20, batch_size=batch_size)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', round(test_acc, 4))

# Step 7: Get predictions and compute the confusion matrix
y_pred = model.predict(x_test, batch_size=batch_size)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels
y_true = np.argmax(y_test, axis=1)  # Convert true labels to class labels

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)

# Print confusion matrix in the desired format
print("Confusion Matrix:")
print(cm)

# Calculate precision and recall
precision = precision_score(y_true, y_pred_classes, average='weighted')
recall = recall_score(y_true, y_pred_classes, average='weighted')

# Print precision and recall
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Data for plotting comparison
models = ['KNN', 'SVM', 'CNN']
accuracy = [90, 98, 93]  # Example accuracies for the three models
precision = [90, 98, 93]  # Example precision for the three models
recall = [93, 98, 92]  # Example recall for the three models

# Bar plot for comparison
x = np.arange(len(models))
width = 0.2

fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(x - width, accuracy, width, label='Accuracy')
ax.bar(x, precision, width, label='Precision')
ax.bar(x + width, recall, width, label='Recall')

# Formatting
ax.set_xlabel('Model')
ax.set_ylabel('Performance (%)')
ax.set_title('Comparison of KNN, SVM, and CNN Performance Metrics')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

plt.show()